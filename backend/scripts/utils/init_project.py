#!/usr/bin/env python3
"""
é»„é‡‘å¸‚åœºåˆ†æç³»ç»Ÿ - é¡¹ç›®åˆå§‹åŒ–è„šæœ¬
è‡ªåŠ¨åˆ›å»ºæ‰€æœ‰å¿…è¦çš„ç›®å½•å’Œæ–‡ä»¶
"""

import os
import sys
from pathlib import Path

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent
BACKEND_DIR = PROJECT_ROOT / "backend"

def create_file(filepath: str, content: str):
    """åˆ›å»ºæ–‡ä»¶"""
    path = Path(filepath)
    path.parent.mkdir(parents=True, exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        f.write(content)
    print(f"âœ… åˆ›å»ºæ–‡ä»¶: {filepath}")

def main():
    print("ğŸš€ å¼€å§‹åˆ›å»ºé»„é‡‘å¸‚åœºåˆ†æç³»ç»Ÿé¡¹ç›®...")
    print("=" * 60)

    # 1. åˆ›å»ºç›®å½•ç»“æ„
    directories = [
        "app",
        "app/models",
        "app/schemas",
        "app/routers",
        "app/agents",
        "app/services",
        "app/utils",
        "app/tasks",
    ]

    for dir_path in directories:
        full_path = BACKEND_DIR / dir_path
        full_path.mkdir(parents=True, exist_ok=True)
        print(f"âœ… åˆ›å»ºç›®å½•: {dir_path}")

    print("\n" + "=" * 60)
    print("ğŸ“ åˆ›å»ºæ ¸å¿ƒæ–‡ä»¶...")
    print("=" * 60)

    # 2. åˆ›å»º __init__.py æ–‡ä»¶
    init_files = [
        "app/__init__.py",
        "app/models/__init__.py",
        "app/schemas/__init__.py",
        "app/routers/__init__.py",
        "app/agents/__init__.py",
        "app/services/__init__.py",
        "app/utils/__init__.py",
        "app/tasks/__init__.py",
    ]

    for file_path in init_files:
        create_file(BACKEND_DIR / file_path, '"""é»„é‡‘å¸‚åœºåˆ†æç³»ç»Ÿ"""')

    # 3. åˆ›å»ºä¸»åº”ç”¨æ–‡ä»¶
    create_file(
        BACKEND_DIR / "app/main.py",
        '''"""FastAPI ä¸»åº”ç”¨å…¥å£"""
import os
from contextlib import asynccontextmanager
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from loguru import logger

from app.config import settings
from app.database import engine, Base
from app.routers import gold_prices, analysis, news, predictions
from app.scheduler import init_scheduler, shutdown_scheduler


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # å¯åŠ¨æ—¶
    logger.info("ğŸš€ å¯åŠ¨é»„é‡‘å¸‚åœºåˆ†æç³»ç»Ÿ...")
    
    # åˆ›å»ºæ•°æ®åº“è¡¨
    Base.metadata.create_all(bind=engine)
    logger.info("âœ… æ•°æ®åº“è¡¨åˆ›å»ºå®Œæˆ")
    
    # åˆå§‹åŒ–è°ƒåº¦å™¨
    if settings.SCHEDULER_ENABLED:
        init_scheduler()
        logger.info("âœ… å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²å¯åŠ¨")
    
    yield
    
    # å…³é—­æ—¶
    logger.info("ğŸ›‘ å…³é—­é»„é‡‘å¸‚åœºåˆ†æç³»ç»Ÿ...")
    shutdown_scheduler()


app = FastAPI(
    title="é»„é‡‘å¸‚åœºåˆ†æç³»ç»Ÿ",
    description="åŸºäºAIçš„é»„é‡‘å¸‚åœºåˆ†æå¹³å°ï¼Œæä¾›å®æ—¶æ•°æ®ã€å¸‚åœºåˆ†æå’Œä»·æ ¼é¢„æµ‹",
    version="1.0.0",
    lifespan=lifespan
)

# CORS é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ³¨å†Œè·¯ç”±
app.include_router(gold_prices.router, prefix="/api/gold", tags=["é»„é‡‘ä»·æ ¼"])
app.include_router(analysis.router, prefix="/api/gold", tags=["å¸‚åœºåˆ†æ"])
app.include_router(news.router, prefix="/api/gold", tags=["æ–°é—»èµ„è®¯"])
app.include_router(predictions.router, prefix="/api/gold", tags=["ä»·æ ¼é¢„æµ‹"])


@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "é»„é‡‘å¸‚åœºåˆ†æç³»ç»Ÿ API",
        "version": "1.0.0",
        "docs": "/docs"
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "healthy", "service": "gold-analysis-api"}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "app.main:app",
        host=settings.APP_HOST,
        port=settings.APP_PORT,
        reload=settings.DEBUG
    )
'''
    )

    # 4. åˆ›å»ºé…ç½®æ–‡ä»¶
    create_file(
        BACKEND_DIR / "app/config.py",
        '''"""é…ç½®ç®¡ç†"""
import os
from pathlib import Path
from typing import Optional
from pydantic_settings import BaseSettings
from dotenv import load_dotenv

load_dotenv()


class Settings(BaseSettings):
    """åº”ç”¨é…ç½®"""
    
    # æ•°æ®åº“é…ç½®
    DATABASE_URL: str = "mysql+pymysql://root:root123@localhost:3306/gold_analysis"
    
    # LLM é…ç½®
    LLM_PROVIDER: str = "deepseek"
    DEEPSEEK_API_KEY: str = "sk-d655427bbfb24d6aa3b074a70d95857c"
    DEEPSEEK_BASE_URL: str = "https://api.deepseek.com/v1"
    
    # åº”ç”¨é…ç½®
    APP_HOST: str = "0.0.0.0"
    APP_PORT: int = 8000
    DEBUG: bool = True
    SECRET_KEY: str = "your-secret-key-change-in-production"
    
    # è°ƒåº¦å™¨é…ç½®
    SCHEDULER_ENABLED: bool = True
    SCHEDULER_TIMEZONE: str = "Asia/Shanghai"
    
    # æ•°æ®æ›´æ–°é…ç½®
    UPDATE_PRICE_CRON: str = "0 * * * *"
    UPDATE_NEWS_CRON: str = "0 */2 * * *"
    UPDATE_ANALYSIS_CRON: str = "0 8 * * *"
    
    class Config:
        env_file = ".env"
        case_sensitive = True


settings = Settings()


def get_llm_config():
    """è·å–LLMé…ç½®"""
    return {
        "provider": settings.LLM_PROVIDER,
        "api_key": settings.DEEPSEEK_API_KEY,
        "base_url": settings.DEEPSEEK_BASE_URL
    }
'''
    )

    # 5. åˆ›å»ºæ•°æ®åº“è¿æ¥æ–‡ä»¶
    create_file(
        BACKEND_DIR / "app/database.py",
        '''"""æ•°æ®åº“è¿æ¥å’Œæ¨¡å‹åŸºç±»"""
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, declarative_base
from app.config import settings

engine = create_engine(
    settings.DATABASE_URL,
    pool_pre_ping=True,
    pool_recycle=3600,
    echo=settings.DEBUG
)

SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

Base = declarative_base()


def get_db():
    """è·å–æ•°æ®åº“ä¼šè¯"""
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


def init_db():
    """åˆå§‹åŒ–æ•°æ®åº“"""
    Base.metadata.create_all(bind=engine)
'''
    )

    # 6. åˆ›å»ºæ•°æ®åº“æ¨¡å‹
    create_file(
        BACKEND_DIR / "app/models/gold_price.py",
        '''"""é»„é‡‘ä»·æ ¼æ•°æ®æ¨¡å‹"""
from sqlalchemy import Column, Integer, String, Float, DateTime, Date, Text, Enum
from sqlalchemy.sql import func
from app.database import Base
import enum


class PriceType(enum.Enum):
    DAILY = "daily"
    MONTHLY = "monthly"


class GoldPrice(Base):
    """é»„é‡‘ä»·æ ¼è¡¨"""
    __tablename__ = "gold_prices"
    
    id = Column(Integer, primary_key=True, index=True)
    date = Column(Date, unique=True, nullable=False, index=True)
    open_price = Column(Float)
    high_price = Column(Float)
    low_price = Column(Float)
    close_price = Column(Float, nullable=False)
    volume = Column(Integer)
    change_percent = Column(Float)
    created_at = Column(DateTime, server_default=func.now())
    updated_at = Column(DateTime, server_default=func.now(), onupdate=func.now())
    
    def __repr__(self):
        return f"<GoldPrice(date={self.date}, close={self.close_price})>"


class DollarIndex(Base):
    """ç¾å…ƒæŒ‡æ•°è¡¨"""
    __tablename__ = "dollar_index"
    
    id = Column(Integer, primary_key=True, index=True)
    date = Column(Date, unique=True, nullable=False, index=True)
    open_price = Column(Float)
    high_price = Column(Float)
    low_price = Column(Float)
    close_price = Column(Float, nullable=False)
    created_at = Column(DateTime, server_default=func.now())
    updated_at = Column(DateTime, server_default=func.now(), onupdate=func.now())
    
    def __repr__(self):
        return f"<DollarIndex(date={self.date}, close={self.close_price})>"
'''
    )

    create_file(
        BACKEND_DIR / "app/models/news.py",
        '''"""æ–°é—»èµ„è®¯æ•°æ®æ¨¡å‹"""
from sqlalchemy import Column, Integer, String, Float, DateTime, Text, Enum
from sqlalchemy.sql import func
from app.database import Base
import enum


class SentimentType(enum.Enum):
    POSITIVE = "positive"
    NEGATIVE = "negative"
    NEUTRAL = "neutral"


class GoldNews(Base):
    """é»„é‡‘æ–°é—»è¡¨"""
    __tablename__ = "gold_news"
    
    id = Column(Integer, primary_key=True, index=True)
    title = Column(String(500), nullable=False)
    content = Column(Text)
    source = Column(String(100))
    url = Column(String(500))
    published_at = Column(DateTime, index=True)
    sentiment = Column(Enum(SentimentType), default=SentimentType.NEUTRAL)
    keywords = Column(Text)
    created_at = Column(DateTime, server_default=func.now())
    
    def __repr__(self):
        return f"<GoldNews(title={self.title[:30]}...)>"
'''
    )

    create_file(
        BACKEND_DIR / "app/models/analysis.py",
        '''"""å¸‚åœºåˆ†ææ•°æ®æ¨¡å‹"""
from sqlalchemy import Column, Integer, String, Float, DateTime, Text, JSON, Enum
from sqlalchemy.sql import func
from app.database import Base
import enum


class FactorType(enum.Enum):
    BULLISH = "bullish"
    BEARISH = "bearish"


class ImpactLevel(enum.Enum):
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"


class MarketFactor(Base):
    """å¸‚åœºå› ç´ è¡¨"""
    __tablename__ = "market_factors"
    
    id = Column(Integer, primary_key=True, index=True)
    factor_type = Column(Enum(FactorType), nullable=False, index=True)
    title = Column(String(200), nullable=False)
    subtitle = Column(String(200))
    description = Column(Text)
    details = Column(JSON)  # å­˜å‚¨ä¸ºJSONæ•°ç»„
    impact = Column(Enum(ImpactLevel), default=ImpactLevel.MEDIUM)
    source = Column(String(200))
    confidence = Column(Float, default=0.8)
    created_at = Column(DateTime, server_default=func.now())
    updated_at = Column(DateTime, server_default=func.now(), onupdate=func.now())
    
    def __repr__(self):
        return f"<MarketFactor(type={self.factor_type}, title={self.title})>"


class InstitutionView(Base):
    """æœºæ„è§‚ç‚¹è¡¨"""
    __tablename__ = "institution_views"
    
    id = Column(Integer, primary_key=True, index=True)
    institution_name = Column(String(100), nullable=False)
    logo = Column(String(50))
    rating = Column(String(20), nullable=False)  # bullish, bearish, neutral
    target_price = Column(Float)
    timeframe = Column(String(50))
    reasoning = Column(Text)
    key_points = Column(JSON)  # å­˜å‚¨ä¸ºJSONæ•°ç»„
    source_url = Column(String(500))
    created_at = Column(DateTime, server_default=func.now())
    updated_at = Column(DateTime, server_default=func.now(), onupdate=func.now())
    
    def __repr__(self):
        return f"<InstitutionView(name={self.institution_name}, target={self.target_price})>"


class Prediction(Base):
    """ä»·æ ¼é¢„æµ‹è¡¨"""
    __tablename__ = "predictions"
    
    id = Column(Integer, primary_key=True, index=True)
    prediction_type = Column(String(50), nullable=False)
    target_price = Column(Float, nullable=False)
    confidence = Column(Float)
    timeframe = Column(String(50))
    reasoning = Column(Text)
    factors = Column(JSON)
    created_at = Column(DateTime, server_default=func.now())
    
    def __repr__(self):
        return f"<Prediction(price={self.target_price}, confidence={self.confidence})>"
'''
    )

    create_file(
        BACKEND_DIR / "app/models/update_log.py",
        '''"""æ•°æ®æ›´æ–°æ—¥å¿—æ¨¡å‹"""
from sqlalchemy import Column, Integer, String, DateTime, Text, Enum
from sqlalchemy.sql import func
from app.database import Base
import enum


class UpdateStatus(enum.Enum):
    SUCCESS = "success"
    FAILED = "failed"


class UpdateLog(Base):
    """æ•°æ®æ›´æ–°æ—¥å¿—è¡¨"""
    __tablename__ = "update_logs"
    
    id = Column(Integer, primary_key=True, index=True)
    data_type = Column(String(50), nullable=False, index=True)
    status = Column(Enum(UpdateStatus), nullable=False)
    records_affected = Column(Integer)
    error_message = Column(Text)
    duration_seconds = Column(Float)
    created_at = Column(DateTime, server_default=func.now())
    
    def __repr__(self):
        return f"<UpdateLog(type={self.data_type}, status={self.status})>"
'''
    )

    print("\n" + "=" * 60)
    print("ğŸ‰ é¡¹ç›®ç»“æ„åˆ›å»ºå®Œæˆ!")
    print("=" * 60)
    print("\nä¸‹ä¸€æ­¥æ“ä½œ:")
    print("1. å®‰è£…ä¾èµ–: pip install -r requirements.txt")
    print("2. åˆ›å»ºæ•°æ®åº“: mysql -u root -p < schema.sql")
    print("3. å¯åŠ¨æœåŠ¡: python -m uvicorn app.main:app --reload")
    print("\næˆ–ä½¿ç”¨ Docker:")
    print("1. docker-compose up -d")


if __name__ == "__main__":
    main()
'''
    )

    # 7. åˆ›å»º Pydantic schemas
    create_file(
        BACKEND_DIR / "app/schemas/gold_price.py",
        '''"""Pydantic æ•°æ®æ¨¡å‹"""
from datetime import datetime, date
from typing import List, Optional
from pydantic import BaseModel, Field
from enum import Enum


class PriceBase(BaseModel):
    """ä»·æ ¼åŸºç¡€æ¨¡å‹"""
    date: date
    open_price: Optional[float] = None
    high_price: Optional[float] = None
    low_price: Optional[float] = None
    close_price: float
    volume: Optional[int] = None


class PriceCreate(PriceBase):
    """åˆ›å»ºä»·æ ¼æ•°æ®"""
    pass


class PriceResponse(PriceBase):
    """ä»·æ ¼å“åº”æ¨¡å‹"""
    id: int
    change_percent: Optional[float] = None
    created_at: datetime
    
    class Config:
        from_attributes = True


class DailyPriceResponse(BaseModel):
    """æ—¥çº¿æ•°æ®å“åº”"""
    date: str
    price: float
    volume: int


class MonthlyPriceResponse(BaseModel):
    """æœˆåº¦æ•°æ®å“åº”"""
    month: str
    open: float
    close: float
    change: float


class CorrelationDataResponse(BaseModel):
    """ç›¸å…³æ€§æ•°æ®å“åº”"""
    date: str
    gold_price: float
    dollar_index: float


class GoldStatsResponse(BaseModel):
    """ç»Ÿè®¡æ•°æ®å“åº”"""
    start_price: float
    end_price: float
    max_price: float
    min_price: float
    total_return: float
    max_date: str
    min_date: str
'''
    )

    create_file(
        BACKEND_DIR / "app/schemas/news.py",
        '''"""æ–°é—» Pydantic æ¨¡å‹"""
from datetime import datetime
from typing import Optional
from pydantic import BaseModel
from enum import Enum


class SentimentEnum(str, Enum):
    POSITIVE = "positive"
    NEGATIVE = "negative"
    NEUTRAL = "neutral"


class NewsBase(BaseModel):
    """æ–°é—»åŸºç¡€æ¨¡å‹"""
    title: str
    content: Optional[str] = None
    source: Optional[str] = None
    url: Optional[str] = None
    published_at: Optional[datetime] = None


class NewsCreate(NewsBase):
    """åˆ›å»ºæ–°é—»"""
    pass


class NewsResponse(NewsBase):
    """æ–°é—»å“åº”æ¨¡å‹"""
    id: int
    sentiment: SentimentEnum
    keywords: Optional[str] = None
    created_at: datetime
    
    class Config:
        from_attributes = True


class NewsFilter(BaseModel):
    """æ–°é—»è¿‡æ»¤æ¡ä»¶"""
    source: Optional[str] = None
    sentiment: Optional[SentimentEnum] = None
    start_date: Optional[datetime] = None
    end_date: Optional[datetime] = None
    limit: int = 20
'''
    )

    create_file(
        BACKEND_DIR / "app/schemas/analysis.py",
        '''"""åˆ†æ Pydantic æ¨¡å‹"""
from datetime import datetime
from typing import List, Optional
from pydantic import BaseModel
from enum import Enum


class FactorTypeEnum(str, Enum):
    BULLISH = "bullish"
    BEARISH = "bearish"


class ImpactEnum(str, Enum):
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"


class FactorBase(BaseModel):
    """å› ç´ åŸºç¡€æ¨¡å‹"""
    title: str
    subtitle: Optional[str] = None
    description: Optional[str] = None
    details: List[str]
    impact: ImpactEnum


class FactorCreate(FactorBase):
    """åˆ›å»ºå› ç´ """
    factor_type: FactorTypeEnum


class FactorResponse(FactorBase):
    """å› ç´ å“åº”æ¨¡å‹"""
    id: int
    factor_type: FactorTypeEnum
    created_at: datetime
    updated_at: datetime
    
    class Config:
        from_attributes = True


class InstitutionBase(BaseModel):
    """æœºæ„åŸºç¡€æ¨¡å‹"""
    institution_name: str
    logo: Optional[str] = None
    rating: str
    target_price: float
    timeframe: str
    reasoning: str
    key_points: List[str]


class InstitutionCreate(InstitutionBase):
    """åˆ›å»ºæœºæ„è§‚ç‚¹"""
    pass


class InstitutionResponse(InstitutionBase):
    """æœºæ„è§‚ç‚¹å“åº”æ¨¡å‹"""
    id: int
    created_at: datetime
    updated_at: datetime
    
    class Config:
        from_attributes = True


class PredictionBase(BaseModel):
    """é¢„æµ‹åŸºç¡€æ¨¡å‹"""
    prediction_type: str
    target_price: float
    confidence: Optional[float] = None
    timeframe: str
    reasoning: str
    factors: Optional[List[str]] = None


class PredictionCreate(PredictionBase):
    """åˆ›å»ºé¢„æµ‹"""
    pass


class PredictionResponse(PredictionBase):
    """é¢„æµ‹å“åº”æ¨¡å‹"""
    id: int
    created_at: datetime
    
    class Config:
        from_attributes = True
'''
    )

    # 8. åˆ›å»º API è·¯ç”±
    create_file(
        BACKEND_DIR / "app/routers/gold_prices.py",
        '''"""é»„é‡‘ä»·æ ¼ API è·¯ç”±"""
from datetime import datetime, timedelta
from typing import List, Optional
from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy.orm import Session
from app.database import get_db
from app.models.gold_price import GoldPrice, DollarIndex
from app.schemas.gold_price import (
    DailyPriceResponse,
    MonthlyPriceResponse,
    CorrelationDataResponse,
    GoldStatsResponse
)
from app.services.gold_service import GoldService

router = APIRouter()


@router.get("/prices/daily", response_model=List[DailyPriceResponse])
async def get_daily_prices(
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    limit: int = Query(default=100, le=500),
    db: Session = Depends(get_db)
):
    """è·å–æ—¥çº¿ä»·æ ¼æ•°æ®"""
    service = GoldService(db)
    
    if start_date:
        start = datetime.strptime(start_date, "%Y-%m-%d")
    else:
        start = datetime.now() - timedelta(days=limit)
    
    if end_date:
        end = datetime.strptime(end_date, "%Y-%m-%d")
    else:
        end = datetime.now()
    
    prices = service.get_daily_prices(start, end)
    
    return [
        DailyPriceResponse(
            date=p.date.strftime("%Y-%m-%d"),
            price=p.close_price,
            volume=p.volume or 0
        )
        for p in prices
    ]


@router.get("/prices/monthly", response_model=List[MonthlyPriceResponse])
async def get_monthly_prices(
    limit: int = Query(default=12, le=60),
    db: Session = Depends(get_db)
):
    """è·å–æœˆåº¦ä»·æ ¼æ•°æ®"""
    service = GoldService(db)
    monthly_data = service.get_monthly_summary(limit)
    
    return [
        MonthlyPriceResponse(
            month=item["month"],
            open=item["open"],
            close=item["close"],
            change=item["change"]
        )
        for item in monthly_data
    ]


@router.get("/prices/correlation", response_model=List[CorrelationDataResponse])
async def get_correlation_data(
    limit: int = Query(default=100, le=500),
    db: Session = Depends(get_db)
):
    """è·å–é»„é‡‘ä¸ç¾å…ƒæŒ‡æ•°ç›¸å…³æ€§æ•°æ®"""
    service = GoldService(db)
    correlation_data = service.get_correlation_data(limit)
    
    return [
        CorrelationDataResponse(
            date=item["date"],
            gold_price=item["gold_price"],
            dollar_index=item["dollar_index"]
        )
        for item in correlation_data
    ]


@router.get("/stats", response_model=GoldStatsResponse)
async def get_gold_stats(db: Session = Depends(get_db)):
    """è·å–é»„é‡‘ç»Ÿè®¡æ•°æ®"""
    service = GoldService(db)
    stats = service.get_statistics()
    
    if not stats:
        raise HTTPException(status_code=404, detail="æš‚æ— æ•°æ®")
    
    return GoldStatsResponse(**stats)


@router.get("/latest")
async def get_latest_price(db: Session = Depends(get_db)):
    """è·å–æœ€æ–°ä»·æ ¼"""
    service = GoldService(db)
    latest = service.get_latest_price()
    
    if not latest:
        raise HTTPException(status_code=404, detail="æš‚æ— æ•°æ®")
    
    return {
        "date": latest.date.strftime("%Y-%m-%d"),
        "price": latest.close_price,
        "change": latest.change_percent
    }
'''
    )

    create_file(
        BACKEND_DIR / "app/routers/news.py",
        '''"""æ–°é—» API è·¯ç”±"""
from typing import List, Optional
from fastapi import APIRouter, Depends, Query
from sqlalchemy.orm import Session
from app.database import get_db
from app.models.news import GoldNews, SentimentType
from app.schemas.news import NewsResponse, NewsFilter
from app.services.news_service import NewsService

router = APIRouter()


@router.get("/news", response_model=List[NewsResponse])
async def get_news(
    limit: int = Query(default=20, le=100),
    source: Optional[str] = None,
    sentiment: Optional[str] = None,
    db: Session = Depends(get_db)
):
    """è·å–æ–°é—»åˆ—è¡¨"""
    service = NewsService(db)
    
    filter_params = NewsFilter(
        source=source,
        sentiment=sentiment if sentiment else None,
        limit=limit
    )
    
    news = service.get_news(filter_params)
    
    return [
        NewsResponse(
            id=n.id,
            title=n.title,
            content=n.content,
            source=n.source,
            url=n.url,
            published_at=n.published_at,
            sentiment=n.sentiment,
            keywords=n.keywords,
            created_at=n.created_at
        )
        for n in news
    ]


@router.get("/news/{news_id}")
async def get_news_detail(news_id: int, db: Session = Depends(get_db)):
    """è·å–æ–°é—»è¯¦æƒ…"""
    service = NewsService(db)
    news = service.get_news_by_id(news_id)
    
    if not news:
        return {"error": "æ–°é—»ä¸å­˜åœ¨"}
    
    return {
        "id": news.id,
        "title": news.title,
        "content": news.content,
        "source": news.source,
        "url": news.url,
        "published_at": news.published_at,
        "sentiment": news.sentiment,
        "keywords": news.keywords
    }


@router.get("/news/sentiment/summary")
async def get_sentiment_summary(db: Session = Depends(get_db)):
    """è·å–æƒ…æ„Ÿåˆ†ææ‘˜è¦"""
    service = NewsService(db)
    summary = service.get_sentiment_summary()
    
    if not summary:
        return {"positive": 0, "neutral": 0, "negative": 0}
    
    return summary
'''
    )

    create_file(
        BACKEND_DIR / "app/routers/analysis.py",
        '''"""å¸‚åœºåˆ†æ API è·¯ç”±"""
from typing import List, Optional
from fastapi import APIRouter, Depends
from sqlalchemy.orm import Session
from app.database import get_db
from app.models.analysis import MarketFactor, InstitutionView
from app.schemas.analysis import (
    FactorResponse,
    InstitutionResponse
)

router = APIRouter()


@router.get("/factors", response_model=List[FactorResponse])
async def get_market_factors(
    factor_type: Optional[str] = None,
    limit: int = 10,
    db: Session = Depends(get_db)
):
    """è·å–å¸‚åœºå› ç´ """
    query = db.query(MarketFactor)
    
    if factor_type:
        query = query.filter(MarketFactor.factor_type == factor_type)
    
    factors = query.order_by(MarketFactor.created_at.desc()).limit(limit).all()
    
    return [
        FactorResponse(
            id=f.id,
            factor_type=f.factor_type,
            title=f.title,
            subtitle=f.subtitle,
            description=f.description,
            details=f.details or [],
            impact=f.impact,
            created_at=f.created_at,
            updated_at=f.updated_at
        )
        for f in factors
    ]


@router.get("/factors/bullish", response_model=List[FactorResponse])
async def get_bullish_factors(
    limit: int = 10,
    db: Session = Depends(get_db)
):
    """è·å–çœ‹æ¶¨å› ç´ """
    factors = db.query(MarketFactor).filter(
        MarketFactor.factor_type == "bullish"
    ).order_by(MarketFactor.created_at.desc()).limit(limit).all()
    
    return [
        FactorResponse(
            id=f.id,
            factor_type=f.factor_type,
            title=f.title,
            subtitle=f.subtitle,
            description=f.description,
            details=f.details or [],
            impact=f.impact,
            created_at=f.created_at,
            updated_at=f.updated_at
        )
        for f in factors
    ]


@router.get("/factors/bearish", response_model=List[FactorResponse])
async def get_bearish_factors(
    limit: int = 10,
    db: Session = Depends(get_db)
):
    """è·å–çœ‹è·Œå› ç´ """
    factors = db.query(MarketFactor).filter(
        MarketFactor.factor_type == "bearish"
    ).order_by(MarketFactor.created_at.desc()).limit(limit).all()
    
    return [
        FactorResponse(
            id=f.id,
            factor_type=f.factor_type,
            title=f.title,
            subtitle=f.subtitle,
            description=f.description,
            details=f.details or [],
            impact=f.impact,
            created_at=f.created_at,
            updated_at=f.updated_at
        )
        for f in factors
    ]


@router.get("/institutions", response_model=List[InstitutionResponse])
async def get_institution_views(
    limit: int = 10,
    db: Session = Depends(get_db)
):
    """è·å–æœºæ„è§‚ç‚¹"""
    views = db.query(InstitutionView).order_by(
        InstitutionView.created_at.desc()
    ).limit(limit).all()
    
    return [
        InstitutionResponse(
            id=v.id,
            institution_name=v.institution_name,
            logo=v.logo,
            rating=v.rating,
            target_price=v.target_price,
            timeframe=v.timeframe,
            reasoning=v.reasoning,
            key_points=v.key_points or [],
            created_at=v.created_at,
            updated_at=v.updated_at
        )
        for v in views
    ]
'''
    )

    create_file(
        BACKEND_DIR / "app/routers/predictions.py",
        '''"""ä»·æ ¼é¢„æµ‹ API è·¯ç”±"""
from typing import List, Optional
from fastapi import APIRouter, Depends
from sqlalchemy.orm import Session
from app.database import get_db
from app.models.analysis import Prediction
from app.schemas.analysis import PredictionResponse

router = APIRouter()


@router.get("/predictions", response_model=List[PredictionResponse])
async def get_predictions(
    limit: int = 10,
    db: Session = Depends(get_db)
):
    """è·å–ä»·æ ¼é¢„æµ‹"""
    predictions = db.query(Prediction).order_by(
        Prediction.created_at.desc()
    ).limit(limit).all()
    
    return [
        PredictionResponse(
            id=p.id,
            prediction_type=p.prediction_type,
            target_price=p.target_price,
            confidence=p.confidence,
            timeframe=p.timeframe,
            reasoning=p.reasoning,
            factors=p.factors,
            created_at=p.created_at
        )
        for p in predictions
    ]


@router.get("/predictions/latest")
async def get_latest_prediction(db: Session = Depends(get_db)):
    """è·å–æœ€æ–°é¢„æµ‹"""
    prediction = db.query(Prediction).order_by(
        Prediction.created_at.desc()
    ).first()
    
    if not prediction:
        return {"message": "æš‚æ— é¢„æµ‹æ•°æ®"}
    
    return {
        "type": prediction.prediction_type,
        "target_price": prediction.target_price,
        "confidence": prediction.confidence,
        "timeframe": prediction.timeframe,
        "reasoning": prediction.reasoning,
        "factors": prediction.factors,
        "created_at": prediction.created_at
    }
'''
    )

    # 9. åˆ›å»ºæœåŠ¡å±‚
    create_file(
        BACKEND_DIR / "app/services/gold_service.py",
        '''"""é»„é‡‘ä»·æ ¼æœåŠ¡"""
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from sqlalchemy.orm import Session
from sqlalchemy import func
from app.models.gold_price import GoldPrice, DollarIndex

import yfinance as yf


class GoldService:
    """é»„é‡‘ä»·æ ¼æœåŠ¡"""
    
    def __init__(self, db: Session):
        self.db = db
    
    def get_daily_prices(self, start_date: datetime, end_date: datetime) -> List[GoldPrice]:
        """è·å–æ—¥çº¿ä»·æ ¼"""
        return self.db.query(GoldPrice).filter(
            GoldPrice.date >= start_date.date(),
            GoldPrice.date <= end_date.date()
        ).order_by(GoldPrice.date).all()
    
    def get_monthly_summary(self, months: int = 12) -> List[Dict]:
        """è·å–æœˆåº¦æ±‡æ€»"""
        # è·å–æœ€è¿‘æœˆä»½çš„æ•°æ®
        prices = self.db.query(GoldPrice).order_by(
            GoldPrice.date.desc()
        ).limit(months * 30).all()
        
        # æŒ‰æœˆä»½åˆ†ç»„
        monthly_data = {}
        for price in prices:
            month_key = price.date.strftime("%Y-%m")
            if month_key not in monthly_data:
                monthly_data[month_key] = {
                    "month": month_key,
                    "open": None,
                    "close": None,
                    "min": float('inf'),
                    "max": float('-inf')
                }
            
            if monthly_data[month_key]["open"] is None:
                monthly_data[month_key]["open"] = price.open_price or price.close_price
            monthly_data[month_key]["close"] = price.close_price
            monthly_data[month_key]["min"] = min(
                monthly_data[month_key]["min"],
                price.low_price or price.close_price
            )
            monthly_data[month_key]["max"] = max(
                monthly_data[month_key]["max"],
                price.high_price or price.close_price
            )
        
        # è®¡ç®—æ¶¨è·Œ
        result = []
        for month_key in sorted(monthly_data.keys(), reverse=True):
            data = monthly_data[month_key]
            change = ((data["close"] - data["open"]) / data["open"] * 100) if data["open"] else 0
            result.append({
                "month": month_key,
                "open": round(data["open"], 2),
                "close": round(data["close"], 2),
                "change": round(change, 2)
            })
        
        return result[:months]
    
    def get_correlation_data(self, limit: int = 100) -> List[Dict]:
        """è·å–ç›¸å…³æ€§æ•°æ®"""
        # è·å–é»„é‡‘ä»·æ ¼
        gold_prices = self.db.query(GoldPrice).order_by(
            GoldPrice.date.desc()
        ).limit(limit).all()
        
        # è·å–ç¾å…ƒæŒ‡æ•°
        dollar_prices = self.db.query(DollarIndex).order_by(
            DollarIndex.date.desc()
        ).limit(limit).all()
        
        # è½¬æ¢ä¸ºå­—å…¸
        gold_dict = {p.date.strftime("%Y-%m-%d"): p.close_price for p in gold_prices}
        dollar_dict = {p.date.strftime("%Y-%m-%d"): p.close_price for p in dollar_prices}
        
        # åˆå¹¶æ•°æ®
        result = []
        for date_str in sorted(gold_dict.keys(), reverse=True):
            if date_str in dollar_dict:
                result.append({
                    "date": date_str,
                    "gold_price": gold_dict[date_str],
                    "dollar_index": dollar_dict[date_str]
                })
        
        return result
    
    def get_statistics(self) -> Optional[Dict]:
        """è·å–ç»Ÿè®¡æ•°æ®"""
        prices = self.db.query(GoldPrice).all()
        
        if not prices:
            return None
        
        sorted_prices = sorted(prices, key=lambda x: x.date)
        
        start_price = sorted_prices[0].close_price
        end_price = sorted_prices[-1].close_price
        total_return = ((end_price - start_price) / start_price) * 100
        
        max_price = max(p.close_price for p in prices)
        min_price = min(p.close_price for p in prices)
        
        max_date = next(p.date.strftime("%Y-%m-%d") for p in prices if p.close_price == max_price)
        min_date = next(p.date.strftime("%Y-%m-%d") for p in prices if p.close_price == min_price)
        
        return {
            "start_price": round(start_price, 2),
            "end_price": round(end_price, 2),
            "max_price": round(max_price, 2),
            "min_price": round(min_price, 2),
            "total_return": round(total_return, 2),
            "max_date": max_date,
            "min_date": min_date
        }
    
    def get_latest_price(self) -> Optional[GoldPrice]:
        """è·å–æœ€æ–°ä»·æ ¼"""
        return self.db.query(GoldPrice).order_by(
            GoldPrice.date.desc()
        ).first()
    
    def fetch_and_save_prices(self):
        """ä»Yahoo Financeè·å–å¹¶ä¿å­˜ä»·æ ¼"""
        try:
            # ä¸‹è½½é»„é‡‘ä»·æ ¼æ•°æ®
            gold = yf.Ticker("GLD")
            df = gold.history(period="1y")
            
            for index, row in df.iterrows():
                date = index.date()
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                existing = self.db.query(GoldPrice).filter(
                    GoldPrice.date == date
                ).first()
                
                if existing:
                    continue
                
                gold_price = GoldPrice(
                    date=date,
                    open_price=float(row['Open']),
                    high_price=float(row['High']),
                    low_price=float(row['Low']),
                    close_price=float(row['Close']),
                    volume=int(row['Volume'])
                )
                
                self.db.add(gold_price)
            
            self.db.commit()
            return True
        except Exception as e:
            self.db.rollback()
            raise e
    
    def fetch_and_save_dollar_index(self):
        """ä»Yahoo Financeè·å–å¹¶ä¿å­˜ç¾å…ƒæŒ‡æ•°"""
        try:
            # ä¸‹è½½ç¾å…ƒæŒ‡æ•°æ•°æ®
            dxy = yf.Ticker("DX-Y.NYB")
            df = dxy.history(period="1y")
            
            for index, row in df.iterrows():
                date = index.date()
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                existing = self.db.query(DollarIndex).filter(
                    DollarIndex.date == date
                ).first()
                
                if existing:
                    continue
                
                dollar_index = DollarIndex(
                    date=date,
                    open_price=float(row['Open']),
                    high_price=float(row['High']),
                    low_price=float(row['Low']),
                    close_price=float(row['Close'])
                )
                
                self.db.add(dollar_index)
            
            self.db.commit()
            return True
        except Exception as e:
            self.db.rollback()
            raise e
'''
    )

    create_file(
        BACKEND_DIR / "app/services/news_service.py",
        '''"""æ–°é—»æœåŠ¡"""
from typing import List, Dict, Optional
from sqlalchemy.orm import Session
from app.models.news import GoldNews, SentimentType
import feedparser
import requests


class NewsService:
    """æ–°é—»æœåŠ¡"""
    
    def __init__(self, db: Session):
        self.db = db
    
    def get_news(self, filter_params) -> List[GoldNews]:
        """è·å–æ–°é—»åˆ—è¡¨"""
        query = self.db.query(GoldNews)
        
        if filter_params.source:
            query = query.filter(GoldNews.source == filter_params.source)
        
        if filter_params.sentiment:
            query = query.filter(GoldNews.sentiment == filter_params.sentiment)
        
        if filter_params.start_date:
            query = query.filter(GoldNews.published_at >= filter_params.start_date)
        
        if filter_params.end_date:
            query = query.filter(GoldNews.published_at <= filter_params.end_date)
        
        return query.order_by(GoldNews.published_at.desc()).limit(filter_params.limit).all()
    
    def get_news_by_id(self, news_id: int) -> Optional[GoldNews]:
        """æ ¹æ®IDè·å–æ–°é—»"""
        return self.db.query(GoldNews).filter(GoldNews.id == news_id).first()
    
    def get_sentiment_summary(self) -> Dict[str, int]:
        """è·å–æƒ…æ„Ÿåˆ†ææ‘˜è¦"""
        stats = self.db.query(
            GoldNews.sentiment,
            func.count(GoldNews.id)
        ).group_by(GoldNews.sentiment).all()
        
        return {
            "positive": 0,
            "neutral": 0,
            "negative": 0,
            **{s[0].value: s[1] for s in stats}
        }
    
    def fetch_from_rss(self, rss_url: str, source: str, limit: int = 10) -> List[Dict]:
        """ä»RSSè·å–æ–°é—»"""
        try:
            feed = feedparser.parse(rss_url)
            
            news_list = []
            for entry in feed.entries[:limit]:
                news_list.append({
                    'title': entry.title,
                    'summary': entry.get('summary', ''),
                    'link': entry.link,
                    'published_at': entry.get('published', ''),
                    'source': source
                })
            
            return news_list
        except Exception as e:
            print(f"RSSè·å–å¤±è´¥ {source}: {e}")
            return []
    
    def fetch_all_rss_news(self) -> List[Dict]:
        """ä»æ‰€æœ‰RSSæºè·å–æ–°é—»"""
        all_news = []
        
        rss_sources = [
            ('http://finance.sina.com.cn/roll/finance_gold/index.d.html', 'æ–°æµªè´¢ç»'),
            ('http://www.fx168.com/rss/gold.xml', 'FX168'),
        ]
        
        for rss_url, source in rss_sources:
            try:
                news = self.fetch_from_rss(rss_url, source, limit=5)
                all_news.extend(news)
            except Exception as e:
                print(f"RSSè·å–å¤±è´¥ {source}: {e}")
        
        return all_news
    
    def save_news(self, news_data: Dict):
        """ä¿å­˜æ–°é—»"""
        try:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            existing = self.db.query(GoldNews).filter(
                GoldNews.url == news_data.get('url')
            ).first()
            
            if existing:
                return existing
            
            news = GoldNews(
                title=news_data['title'],
                content=news_data.get('content'),
                source=news_data.get('source'),
                url=news_data.get('url'),
                published_at=news_data.get('published_at'),
                sentiment=SentimentType.NEUTRAL,  # åç»­å¯ç”¨AIåˆ†æ
                keywords=news_data.get('keywords')
            )
            
            self.db.add(news)
            self.db.commit()
            
            return news
        except Exception as e:
            self.db.rollback()
            print(f"ä¿å­˜æ–°é—»å¤±è´¥: {e}")
            return None
'''
    )

    # 10. åˆ›å»º Agent æ¨¡å—
    create_file(
        BACKEND_DIR / "app/agents/base.py",
        '''"""LangChain Agent åŸºç±»"""
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional
from langchain_openai import ChatOpenAI
from app.config import settings


class BaseAgent(ABC):
    """AgentåŸºç±»"""
    
    def __init__(self):
        self.llm = self._create_llm()
    
    def _create_llm(self) -> ChatOpenAI:
        """åˆ›å»ºLLMå®ä¾‹"""
        return ChatOpenAI(
            model="deepseek-chat",
            openai_api_key=settings.DEEPSEEK_API_KEY,
            openai_api_base=settings.DEEPSEEK_BASE_URL,
            temperature=0.7,
            max_tokens=4096
        )
    
    @abstractmethod
    def run(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡ŒAgent"""
        pass
    
    def _format_prompt(self, template: str, **kwargs) -> str:
        """æ ¼å¼åŒ–Prompt"""
        return template.format(**kwargs)
'''
    )

    create_file(
        BACKEND_DIR / "app/agents/market_analyzer.py",
        '''"""å¸‚åœºåˆ†æ Agent"""
from typing import Dict, Any, List
from app.agents.base import BaseAgent


class MarketAnalyzerAgent(BaseAgent):
    """å¸‚åœºåˆ†æ Agent"""
    
    def __init__(self):
        super().__init__()
        self.prompt_template = """
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é»„é‡‘å¸‚åœºåˆ†æå¸ˆã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯è¿›è¡Œåˆ†æï¼š

å½“å‰å¸‚åœºæ•°æ®ï¼š
{market_data}

æœ€æ–°æ–°é—»ï¼š
{news}

è¯·åˆ†æï¼š
1. å½“å‰å¸‚åœºçš„ä¸»è¦çœ‹æ¶¨å› ç´ 
2. å½“å‰å¸‚åœºçš„ä¸»è¦çœ‹è·Œå› ç´ 
3. ä»·æ ¼èµ°åŠ¿é¢„æµ‹
4. æŠ•èµ„å»ºè®®

è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
    "bullish_factors": [
        {{
            "title": "å› ç´ æ ‡é¢˜",
            "subtitle": "å‰¯æ ‡é¢˜",
            "description": "è¯¦ç»†æè¿°",
            "details": ["è¦ç‚¹1", "è¦ç‚¹2"],
            "impact": "high/medium/low"
        }}
    ],
    "bearish_factors": [
        {{
            "title": "å› ç´ æ ‡é¢˜",
            "subtitle": "å‰¯æ ‡é¢˜",
            "description": "è¯¦ç»†æè¿°",
            "details": ["è¦ç‚¹1", "è¦ç‚¹2"],
            "impact": "high/medium/low"
        }}
    ],
    "prediction": {{
        "target_price": 5000,
        "timeframe": "2026å¹´åº•",
        "confidence": 0.8,
        "reasoning": "é¢„æµ‹ç†ç”±"
    }},
    "advice": "æŠ•èµ„å»ºè®®"
}}
"""
    
    def run(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå¸‚åœºåˆ†æ"""
        market_data = input_data.get('market_data', {})
        news = input_data.get('news', [])
        
        news_text = "\n".join([f"- {n.get('title', '')}" for n in news[:10]])
        
        prompt = self._format_prompt(
            self.prompt_template,
            market_data=str(market_data),
            news=news_text
        )
        
        response = self.llm.invoke(prompt)
        
        # è§£æJSONå“åº”
        import json
        try:
            # å°è¯•ç›´æ¥è§£æ
            result = json.loads(response.content)
        except json.JSONDecodeError:
            # å¦‚æœå¤±è´¥ï¼Œå°è¯•æå–JSON
            content = response.content
            start = content.find('{')
            end = content.rfind('}') + 1
            if start != -1 and end != 0:
                result = json.loads(content[start:end])
            else:
                result = {
                    "bullish_factors": [],
                    "bearish_factors": [],
                    "prediction": None,
                    "advice": "åˆ†æå¤±è´¥"
                }
        
        return result
'''
    )

    create_file(
        BACKEND_DIR / "app/agents/news_analyzer.py",
        '''"""æ–°é—»åˆ†æ Agent"""
from typing import Dict, Any, List
from app.agents.base import BaseAgent


class NewsAnalyzerAgent(BaseAgent):
    """æ–°é—»åˆ†æ Agent"""
    
    def __init__(self):
        super().__init__()
        self.prompt_template = """
ä½ æ˜¯ä¸€ä½é‡‘èæ–°é—»åˆ†æå¸ˆã€‚è¯·åˆ†æä»¥ä¸‹é»„é‡‘ç›¸å…³æ–°é—»çš„æƒ…æ„Ÿå’Œé‡è¦æ€§ï¼š

{news_list}

è¯·å¯¹æ¯æ¡æ–°é—»è¿›è¡Œåˆ†æï¼Œä»¥JSONæ ¼å¼è¿”å›ï¼š
[
    {{
        "title": "æ–°é—»æ ‡é¢˜",
        "sentiment": "positive/negative/neutral",
        "importance": "high/medium/low",
        "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"],
        "impact_summary": "å¯¹é»„é‡‘å¸‚åœºçš„å½±å“æ¦‚è¿°"
    }}
]
"""
    
    def run(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæ–°é—»åˆ†æ"""
        news_list = input_data.get('news', [])
        
        news_text = "\n".join([
            f"{i+1}. {n.get('title', '')}"
            for i, n in enumerate(news_list[:20])
        ])
        
        prompt = self._format_prompt(
            self.prompt_template,
            news_list=news_text
        )
        
        response = self.llm.invoke(prompt)
        
        # è§£æJSONå“åº”
        import json
        try:
            content = response.content
            start = content.find('[')
            end = content.rfind(']') + 1
            if start != -1 and end != 0:
                result = json.loads(content[start:end])
            else:
                result = []
        except json.JSONDecodeError:
            result = []
        
        return {"analysis": result}
'''
    )

    # 11. åˆ›å»ºå®šæ—¶ä»»åŠ¡
    create_file(
        BACKEND_DIR / "app/scheduler.py",
        '''"""å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨"""
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from loguru import logger
from app.config import settings

scheduler = AsyncIOScheduler(timezone=settings.SCHEDULER_TIMEZONE)


def init_scheduler():
    """åˆå§‹åŒ–è°ƒåº¦å™¨"""
    if not settings.SCHEDULER_ENABLED:
        logger.info("å®šæ—¶ä»»åŠ¡å·²ç¦ç”¨")
        return
    
    # ä»·æ ¼æ›´æ–°ä»»åŠ¡ - æ¯å°æ—¶
    scheduler.add_job(
        update_prices_job,
        CronTrigger.from_crontab(settings.UPDATE_PRICE_CRON),
        id='update_prices',
        name='æ›´æ–°é»„é‡‘ä»·æ ¼æ•°æ®',
        replace_existing=True
    )
    
    # æ–°é—»æ›´æ–°ä»»åŠ¡ - æ¯2å°æ—¶
    scheduler.add_job(
        update_news_job,
        CronTrigger.from_crontab(settings.UPDATE_NEWS_CRON),
        id='update_news',
        name='æ›´æ–°æ–°é—»èµ„è®¯',
        replace_existing=True
    )
    
    # å¸‚åœºåˆ†æä»»åŠ¡ - æ¯å¤©æ—©ä¸Š8ç‚¹
    scheduler.add_job(
        update_analysis_job,
        CronTrigger.from_crontab(settings.UPDATE_ANALYSIS_CRON),
        id='update_analysis',
        name='æ›´æ–°å¸‚åœºåˆ†æ',
        replace_existing=True
    )
    
    scheduler.start()
    logger.info("å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²å¯åŠ¨")


def shutdown_scheduler():
    """å…³é—­è°ƒåº¦å™¨"""
    if scheduler.running:
        scheduler.shutdown()
        logger.info("å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²å…³é—­")


async def update_prices_job():
    """æ›´æ–°ä»·æ ¼æ•°æ®"""
    logger.info("å¼€å§‹æ›´æ–°é»„é‡‘ä»·æ ¼æ•°æ®...")
    try:
        from app.services.gold_service import GoldService
        from app.database import SessionLocal
        
        db = SessionLocal()
        try:
            service = GoldService(db)
            service.fetch_and_save_prices()
            service.fetch_and_save_dollar_index()
            logger.info("âœ… ä»·æ ¼æ•°æ®æ›´æ–°å®Œæˆ")
        finally:
            db.close()
    except Exception as e:
        logger.error(f"âŒ ä»·æ ¼æ•°æ®æ›´æ–°å¤±è´¥: {e}")


async def update_news_job():
    """æ›´æ–°æ–°é—»æ•°æ®"""
    logger.info("å¼€å§‹æ›´æ–°æ–°é—»èµ„è®¯...")
    try:
        from app.services.news_service import NewsService
        from app.database import SessionLocal
        
        db = SessionLocal()
        try:
            service = NewsService(db)
            news_list = service.fetch_all_rss_news()
            
            for news in news_list:
                service.save_news(news)
            
            logger.info(f"âœ… æ–°é—»æ•°æ®æ›´æ–°å®Œæˆï¼Œå…±{len(news_list)}æ¡")
        finally:
            db.close()
    except Exception as e:
        logger.error(f"âŒ æ–°é—»æ•°æ®æ›´æ–°å¤±è´¥: {e}")


async def update_analysis_job():
    """æ›´æ–°å¸‚åœºåˆ†æ"""
    logger.info("å¼€å§‹æ›´æ–°å¸‚åœºåˆ†æ...")
    try:
        from app.agents.market_analyzer import MarketAnalyzerAgent
        from app.database import SessionLocal
        
        db = SessionLocal()
        try:
            agent = MarketAnalyzerAgent()
            
            # è·å–å¸‚åœºæ•°æ®
            from app.services.gold_service import GoldService
            service = GoldService(db)
            stats = service.get_statistics()
            
            # è·å–æ–°é—»
            from app.services.news_service import NewsService
            news_service = NewsService(db)
            news = news_service.get_news(type('NewsFilter', (), {'limit': 20, 'source': None, 'sentiment': None, 'start_date': None, 'end_date': None})())
            
            news_data = [{'title': n.title, 'content': n.content} for n in news]
            
            # æ‰§è¡Œåˆ†æ
            result = agent.run({
                'market_data': stats or {},
                'news': news_data
            })
            
            logger.info("âœ… å¸‚åœºåˆ†ææ›´æ–°å®Œæˆ")
            logger.info(f"   çœ‹æ¶¨å› ç´ : {len(result.get('bullish_factors', []))}æ¡")
            logger.info(f"   çœ‹è·Œå› ç´ : {len(result.get('bearish_factors', []))}æ¡")
        finally:
            db.close()
    except Exception as e:
        logger.error(f"âŒ å¸‚åœºåˆ†ææ›´æ–°å¤±è´¥: {e}")
'''
    )

    # 12. åˆ›å»º Docker é…ç½®
    create_file(
        BACKEND_DIR / "Dockerfile",
        '''FROM python:3.11-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \\
    default-libmysqlclient-dev \\
    build-essential \\
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¯åŠ¨å‘½ä»¤
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
'''
    )

    create_file(
        BACKEND_DIR / "docker-compose.yml",
        '''version: '3.8'

services:
  mysql:
    image: mysql:8.0
    container_name: gold_mysql
    environment:
      MYSQL_ROOT_PASSWORD: root123
      MYSQL_DATABASE: gold_analysis
      MYSQL_CHARSET: utf8mb4
      MYSQL_COLLATION: utf8mb4_unicode_ci
    ports:
      - "3306:3306"
    volumes:
      - mysql_data:/var/lib/mysql
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      interval: 10s
      timeout: 5s
      retries: 5

  backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: gold_backend
    depends_on:
      mysql:
        condition: service_healthy
    environment:
      - DATABASE_URL=mysql+pymysql://root:root123@mysql:3306/gold_analysis
      - LLM_PROVIDER=deepseek
      - LLM_API_KEY=${LLM_API_KEY}
      - DEBUG=true
    ports:
      - "8000:8000"
    volumes:
      - ./:/app
    command: >
      sh -c "uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload"

volumes:
  mysql_data:
'''
    )

    create_file(
        BACKEND_DIR / ".dockerignore",
        '''__pycache__
*.py[cod]
*$py.class
*.so
.Python
.env
.git
.gitignore
.dockerignore
Dockerfile
docker-compose.yml
*.md
venv/
.venv/
.pytest_cache
.coverage
htmlcov/
.tox/
.mypy_cache/
'''
    )

    create_file(
        BACKEND_DIR / "README.md",
        '''# é»„é‡‘å¸‚åœºåˆ†æç³»ç»Ÿåç«¯

åŸºäº FastAPI + LangChain + MySQL çš„é»„é‡‘å¸‚åœºåˆ†æç³»ç»Ÿåç«¯æœåŠ¡ã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸ“Š **å®æ—¶æ•°æ®è·å–** - ä»Yahoo Financeè·å–é»„é‡‘å’Œç¾å…ƒæŒ‡æ•°æ•°æ®
- ğŸ“° **æ–°é—»èµ„è®¯èšåˆ** - ä»RSSæºèšåˆé»„é‡‘ç›¸å…³æ–°é—»
- ğŸ¤– **AIæ™ºèƒ½åˆ†æ** - ä½¿ç”¨LangChain Agentè¿›è¡Œå¸‚åœºåˆ†æ
- ğŸ“ˆ **ä»·æ ¼é¢„æµ‹** - åŸºäºå†å²æ•°æ®å’Œæ–°é—»çš„AIé¢„æµ‹
- â° **è‡ªåŠ¨æ›´æ–°** - å®šæ—¶ä»»åŠ¡è‡ªåŠ¨æ›´æ–°æ•°æ®

## æŠ€æœ¯æ ˆ

- **FastAPI** - é«˜æ€§èƒ½Webæ¡†æ¶
- **SQLAlchemy** - ORMæ•°æ®åº“æ“ä½œ
- **LangChain** - AI Agentæ¡†æ¶
- **MySQL** - å…³ç³»å‹æ•°æ®åº“
- **APScheduler** - å®šæ—¶ä»»åŠ¡è°ƒåº¦

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

\`\`\`bash
pip install -r requirements.txt
\`\`\`

### 2. é…ç½®ç¯å¢ƒå˜é‡

ç¼–è¾‘ \`.env\` æ–‡ä»¶ï¼š

\`\`\`env
DATABASE_URL=mysql+pymysql://root:root123@localhost:3306/gold_analysis
DEEPSEEK_API_KEY=your_api_key_here
\`\`\`

### 3. åˆ›å»ºæ•°æ®åº“

\`\`\`bash
mysql -u root -p < schema.sql
\`\`\`

### 4. å¯åŠ¨æœåŠ¡

\`\`\`bash
python -m uvicorn app.main:app --reload
\`\`\`

### 5. è®¿é—®APIæ–‡æ¡£

æ‰“å¼€æµè§ˆå™¨è®¿é—®ï¼šhttp://localhost:8000/docs

## Docker éƒ¨ç½²

\`\`\`bash
docker-compose up -d
\`\`\`

## é¡¹ç›®ç»“æ„

\`\`\`
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPIå…¥å£
â”‚   â”œâ”€â”€ config.py            # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ database.py          # æ•°æ®åº“è¿æ¥
â”‚   â”œâ”€â”€ models/              # æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ schemas/             # Pydanticæ¨¡å‹
â”‚   â”œâ”€â”€ routers/             # APIè·¯ç”±
â”‚   â”œâ”€â”€ agents/              # LangChain Agent
â”‚   â”œâ”€â”€ services/            # ä¸šåŠ¡é€»è¾‘
â”‚   â”œâ”€â”€ utils/               # å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ tasks/               # å®šæ—¶ä»»åŠ¡
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ docker-compose.yml
\`\`\`

## API æ¥å£

### é»„é‡‘ä»·æ ¼

- \`GET /api/gold/prices/daily\` - è·å–æ—¥çº¿æ•°æ®
- \`GET /api/gold/prices/monthly\` - è·å–æœˆåº¦æ±‡æ€»
- \`GET /api/gold/prices/correlation\` - è·å–ç›¸å…³æ€§æ•°æ®
- \`GET /api/gold/stats\` - è·å–ç»Ÿè®¡æ•°æ®
- \`GET /api/gold/latest\` - è·å–æœ€æ–°ä»·æ ¼

### æ–°é—»èµ„è®¯

- \`GET /api/gold/news\` - è·å–æ–°é—»åˆ—è¡¨
- \`GET /api/gold/news/{id}\` - è·å–æ–°é—»è¯¦æƒ…
- \`GET /api/gold/news/sentiment/summary\` - æƒ…æ„Ÿåˆ†ææ‘˜è¦

### å¸‚åœºåˆ†æ

- \`GET /api/gold/factors\` - è·å–å¸‚åœºå› ç´ 
- \`GET /api/gold/factors/bullish\` - è·å–çœ‹æ¶¨å› ç´ 
- \`GET /api/gold/factors/bearish\` - è·å–çœ‹è·Œå› ç´ 
- \`GET /api/gold/institutions\` - è·å–æœºæ„è§‚ç‚¹

### ä»·æ ¼é¢„æµ‹

- \`GET /api/gold/predictions\` - è·å–é¢„æµ‹åˆ—è¡¨
- \`GET /api/gold/predictions/latest\` - è·å–æœ€æ–°é¢„æµ‹

## å®šæ—¶ä»»åŠ¡

| ä»»åŠ¡ | é¢‘ç‡ | è¯´æ˜ |
|------|------|------|
| æ›´æ–°ä»·æ ¼ | æ¯å°æ—¶ | è·å–é»„é‡‘å’Œç¾å…ƒæŒ‡æ•°æ•°æ® |
| æ›´æ–°æ–°é—» | æ¯2å°æ—¶ | èšåˆRSSæ–°é—»èµ„è®¯ |
| æ›´æ–°åˆ†æ | æ¯å¤©8ç‚¹ | AIå¸‚åœºåˆ†æå’Œé¢„æµ‹ |

## License

MIT
'''
    )

    create_file(
        BACKEND_DIR / "schema.sql",
        '''-- é»„é‡‘å¸‚åœºåˆ†æç³»ç»Ÿæ•°æ®åº“ Schema
-- åˆ›å»ºæ•°æ®åº“
CREATE DATABASE IF NOT EXISTS gold_analysis CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
USE gold_analysis;

-- é»„é‡‘ä»·æ ¼è¡¨
CREATE TABLE IF NOT EXISTS gold_prices (
    id INT AUTO_INCREMENT PRIMARY KEY,
    date DATE NOT NULL UNIQUE,
    open_price DECIMAL(10, 2),
    high_price DECIMAL(10, 2),
    low_price DECIMAL(10, 2),
    close_price DECIMAL(10, 2) NOT NULL,
    volume INT,
    change_percent DECIMAL(5, 2),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    INDEX idx_date (date)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- ç¾å…ƒæŒ‡æ•°è¡¨
CREATE TABLE IF NOT EXISTS dollar_index (
    id INT AUTO_INCREMENT PRIMARY KEY,
    date DATE NOT NULL UNIQUE,
    open_price DECIMAL(10, 4),
    high_price DECIMAL(10, 4),
    low_price DECIMAL(10, 4),
    close_price DECIMAL(10, 4) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    INDEX idx_date (date)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- é»„é‡‘æ–°é—»è¡¨
CREATE TABLE IF NOT EXISTS gold_news (
    id INT AUTO_INCREMENT PRIMARY KEY,
    title VARCHAR(500) NOT NULL,
    content TEXT,
    source VARCHAR(100),
    url VARCHAR(500),
    published_at TIMESTAMP,
    sentiment ENUM('positive', 'negative', 'neutral') DEFAULT 'neutral',
    keywords TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_published_at (published_at),
    INDEX idx_sentiment (sentiment)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- å¸‚åœºå› ç´ è¡¨
CREATE TABLE IF NOT EXISTS market_factors (
    id INT AUTO_INCREMENT PRIMARY KEY,
    type ENUM('bullish', 'bearish') NOT NULL,
    title VARCHAR(200) NOT NULL,
    subtitle VARCHAR(200),
    description TEXT,
    details JSON,
    impact ENUM('high', 'medium', 'low') DEFAULT 'medium',
    source VARCHAR(200),
    confidence DECIMAL(3, 2) DEFAULT 0.80,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    INDEX idx_type (type)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- æœºæ„è§‚ç‚¹è¡¨
CREATE TABLE IF NOT EXISTS institution_views (
    id INT AUTO_INCREMENT PRIMARY KEY,
    institution_name VARCHAR(100) NOT NULL,
    logo VARCHAR(50),
    rating ENUM('bullish', 'bearish', 'neutral') NOT NULL,
    target_price DECIMAL(10, 2),
    timeframe VARCHAR(50),
    reasoning TEXT,
    key_points JSON,
    source_url VARCHAR(500),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- ä»·æ ¼é¢„æµ‹è¡¨
CREATE TABLE IF NOT EXISTS predictions (
    id INT AUTO_INCREMENT PRIMARY KEY,
    prediction_type VARCHAR(50) NOT NULL,
    target_price DECIMAL(10, 2) NOT NULL,
    confidence DECIMAL(5, 2),
    timeframe VARCHAR(50),
    reasoning TEXT,
    factors JSON,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- æ•°æ®æ›´æ–°æ—¥å¿—è¡¨
CREATE TABLE IF NOT EXISTS update_logs (
    id INT AUTO_INCREMENT PRIMARY KEY,
    data_type VARCHAR(50) NOT NULL,
    status ENUM('success', 'failed') NOT NULL,
    records_affected INT,
    error_message TEXT,
    duration_seconds DECIMAL(10, 3),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_data_type (data_type),
    INDEX idx_status (status)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
'''
    )

    print("\n" + "=" * 60)
    print("ğŸ‰ é¡¹ç›®åˆ›å»ºå®Œæˆ!")
    print("=" * 60)

    print("\nğŸ“‹ ä¸‹ä¸€æ­¥æ“ä½œ:")
    print("-" * 60)
    print("1ï¸âƒ£  è¿›å…¥é¡¹ç›®ç›®å½•: cd backend")
    print("2ï¸âƒ£  å®‰è£…Pythonä¾èµ–: pip install -r requirements.txt")
    print("3ï¸âƒ£  åˆ›å»ºMySQLæ•°æ®åº“: mysql -u root -p < schema.sql")
    print("4ï¸âƒ£  å¯åŠ¨åç«¯æœåŠ¡: python -m uvicorn app.main:app --reload")
    print("")
    print("ğŸ³ æˆ–è€…ä½¿ç”¨Docker:")
    print("   docker-compose up -d")
    print("")
    print("ğŸ“– APIæ–‡æ¡£: http://localhost:8000/docs")
    print("ğŸ¥ å¥åº·æ£€æŸ¥: http://localhost:8000/health")


if __name__ == "__main__":
    main()
